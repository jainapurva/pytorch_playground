[
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        16432.919
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        768.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3311.85
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        768.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2645.13
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        1536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.099
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        33792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.178
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        33792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.107
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34816.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.583
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        33792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.332
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        33792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.117
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34816.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.282
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        33792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.396
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        33792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.075
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34816.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.446
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.487
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        17.041
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45568.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.238
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.344
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        16.425
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45568.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.236
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.489
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.791
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45568.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.236
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.473
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        16.768
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45568.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.548
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.978
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        25.266
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45568.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.853
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.7
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        25.2
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45568.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.825
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.89
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        25.145
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45568.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.998
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.855
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        25.17
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45568.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.431
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        69632.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.599
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        69632.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.275
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        106496.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.181
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        69632.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        16.008
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        69632.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.73
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        106496.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.07
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        69632.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.865
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        69632.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.299
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        106496.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.131
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        69632.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        15.946
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        69632.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.438
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        106496.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.259
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.444
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        16.857
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        37888.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.554
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.223
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        16.574
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        37888.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.486
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.338
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        16.473
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        37888.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.141
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.358
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        16.659
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        37888.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.518
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.669
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.619
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        59392.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.326
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.962
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        23.76
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        59392.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.469
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.796
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.861
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        59392.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.146
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.435
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.236
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        59392.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.285
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.213
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        50.871
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        59392.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.534
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.182
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        51.289
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        59392.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.067
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.614
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        50.258
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        59392.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.177
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.395
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        49.872
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        59392.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.87
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81920.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.653
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81920.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        15.635
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        131072.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.661
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81920.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.364
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81920.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.795
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        131072.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.998
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81920.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.215
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81920.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        14.015
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        131072.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.866
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81920.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.786
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81920.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        15.222
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        131072.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.53
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.482
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        15.181
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.325
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.212
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        15.49
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.204
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.273
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        15.187
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.263
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.428
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        15.262
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.481
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.331
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.6
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        94960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        19.187
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.526
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.318
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95248.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        19.192
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.324
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.196
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        94960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        19.262
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.338
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.379
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        94960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.681
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.672
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.926
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        15.924
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.114
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.656
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        94960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.451
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.488
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        64440.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.118
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.366
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.377
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.127
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        94960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        80.448
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        113536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        76.646
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        113536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.6
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        194304.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        82.971
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        113536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        75.224
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        113536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.656
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        194304.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        79.316
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        113536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        74.871
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        113536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.648
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        194304.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        82.582
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        113536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        74.768
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        113536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.851
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        194304.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        160.015
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        68353.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        149.567
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        175.43
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        165.463
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        141.966
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.674
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        150.081
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        73473.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        213.638
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        168.884
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        162.682
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        72961.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.101
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.079
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.868
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.165
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        129.944
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        140.88
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        73473.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.8
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.186
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.861
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        72961.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.917
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.605
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        150.007
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        143.376
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        219.873
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        156.903
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        73473.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.006
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        216.49
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        148.025
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        72961.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.639
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        159.115
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.016
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        152.672
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        163.034
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        154.807
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        73473.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        152.775
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        163.885
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        157.717
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        87297.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        147.495
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        177.181
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        175.865
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        144.004
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.271
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.996
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112897.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        132.324
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        141.446
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        134.007
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        108801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        138.44
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        211.246
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        149.29
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        176.344
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        179.498
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        157.168
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112897.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        171.269
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        165.676
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        185.983
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        108801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        156.868
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        165.183
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        169.782
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        178.832
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        170.717
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        196.682
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112897.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        167.364
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        186.33
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        146.186
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        108801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        173.11
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        146.788
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        152.938
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        156.2
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        142.512
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        129.998
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112897.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.786
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.012
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        140.897
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        110593.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.971
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        166.363
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        186.781
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        204.425
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        133.024
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        268.609
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121857.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        178.983
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        184.468
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        153.021
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121345.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        161.143
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        157.739
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        174.04
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        161.36
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        164.765
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        179.236
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121857.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.874
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        159.647
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        165.258
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121345.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        147.362
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        167.049
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        165.393
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.044
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        142.448
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.58
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121857.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.476
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.688
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        142.352
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121345.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.85
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        157.011
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        184.89
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        160.5
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.83
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        183.474
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121857.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.569
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.963
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        173.178
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        210945.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        173.401
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        160.966
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        188.61
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        170.361
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        166.897
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        354.771
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        387073.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        353.707
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        352.261
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        165.599
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        382977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        171.574
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        165.744
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        169.783
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        185.353
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        171.731
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        352.569
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        387073.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        357.657
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        350.113
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.027
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        382977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.569
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        139.601
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        133.587
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        166.597
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        185.385
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        351.409
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        387073.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        353.816
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        350.178
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        160.272
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        382977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        151.911
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        145.152
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.989
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        170.812
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        145.633
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        350.028
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        387073.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        352.355
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.961
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.848
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        281089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        151.769
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.693
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        151.586
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.487
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.445
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        131.889
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        83457.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.046
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        134.899
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        144.398
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81409.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        147.119
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.385
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        158.882
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        160.034
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.72
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        149.068
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        83457.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.271
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        153.828
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        157.407
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81409.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        131.954
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.796
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        145.017
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.437
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.385
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        134.636
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        83457.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        125.279
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.861
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.331
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81409.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        131.891
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        134.764
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        165.864
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.512
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.038
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        176.989
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        83457.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        150.992
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        162.598
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        158.477
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        106497.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        148.557
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        134.152
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        153.5
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        149.652
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        143.521
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        215.214
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        144385.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        190.165
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        199.189
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.501
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        128001.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        129.908
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.054
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        138.988
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.872
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.297
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        190.032
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        144385.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        222.561
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        198.091
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        214.993
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        128001.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        144.295
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        154.412
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        142.046
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        154.747
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        149.68
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        211.971
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        144385.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        216.238
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        197.649
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        139.711
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        128001.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        163.166
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        129.075
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.564
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        160.074
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.357
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        207.708
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        144385.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        190.648
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        190.783
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.059
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        135169.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.507
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        140.798
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        179.455
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.515
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.418
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.51
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        180225.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        207.308
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        196.458
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        146.701
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        178177.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        169.76
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        156.202
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        167.489
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        173.519
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        176.404
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        185.005
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        180225.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        191.526
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        205.602
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        163.93
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        178177.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        131.49
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        142.307
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.935
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.948
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.056
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.244
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        180225.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.586
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        206.249
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        143.049
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        178177.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        171.73
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        167.736
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.54
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        153.961
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        142.301
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        193.091
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        180225.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.002
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        185.056
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        155.514
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        157.853
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        154.342
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        129.686
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        147.141
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        144.463
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        942.853
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        466945.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        941.764
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        941.582
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        140.551
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        450561.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.942
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        149.954
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        151.546
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        171.382
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        172.733
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        941.419
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        466945.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        941.823
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        942.911
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        156.467
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        450561.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        142.581
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        134.584
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        157.161
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        150.551
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        151.211
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        943.418
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        466945.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        943.534
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        942.246
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        153.401
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        450561.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.197
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        153.627
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.995
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        149.096
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        170.198
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        943.166
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        466945.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        943.326
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        941.852
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        146.231
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327833.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        148.093
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.315
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        166.23
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        163.612
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        150.042
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        160.204
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        109145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        148.959
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        159.197
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        131.219
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        103145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        146.453
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.824
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.278
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.24
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.739
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.712
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        109145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.357
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        164.576
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        187.439
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        103145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        173.913
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        216.218
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        188.115
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        183.221
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        147.31
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        141.906
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        109145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        145.012
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        160.765
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        133.278
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        103145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        131.18
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        143.627
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        179.627
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        170.985
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        163.246
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        166.798
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        109145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        149.835
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        144.67
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        142.195
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156705.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.243
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156921.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.548
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156921.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        128.134
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156921.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.888
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156921.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        131.229
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157209.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        477.225
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        226497.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        465.925
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        247497.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        465.175
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        247497.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        156.605
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        178209.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.148
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156921.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        134.572
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157497.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        141.573
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157785.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        131.556
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        139.376
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157553.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        478.307
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        225689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        465.078
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        465.182
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.343
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        177401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.101
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.196
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.825
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.878
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.416
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        464.681
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        225401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        462.548
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        247785.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        465.188
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        105.807
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        177689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.873
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.835
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.383
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.765
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157265.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.522
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        465.419
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        225401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        463.727
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        462.111
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.214
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        198689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.058
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.467
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.087
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.008
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.398
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.209
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        330977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.758
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.842
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        125.828
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        324401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        128.491
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        241033.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.761
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240457.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.81
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.075
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        126.092
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.901
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        330689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.475
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.889
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        125.936
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        324401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.569
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.105
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.56
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.545
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.696
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.094
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        330689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.678
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.295
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        169.691
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        324401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        178.87
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        210.905
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        150.086
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        194.947
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        208.145
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.915
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        330689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.302
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        466.69
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        266.569
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        452417.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        265.344
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        268.79
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        259.622
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        257.68
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        256.182
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2134.245
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        672449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2081.09
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2043.401
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        284.52
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        624449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        265.751
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        265.196
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        258.764
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        253.535
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.349
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2144.881
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        672449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2125.098
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2137.059
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        265.238
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        624449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        270.013
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        266.553
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        255.398
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        299.989
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.482
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2123.673
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        672449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2088.967
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2149.907
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        265.541
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        624449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        275.658
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        264.623
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        268.159
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.667
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        257.265
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2010.807
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        672449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2068.011
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2106.113
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  }
]