[
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.579
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34048.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.534
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34048.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.056
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.402
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34048.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.418
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34048.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.24
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.48
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34048.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.659
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34048.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.076
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.242
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34048.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.53
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34048.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.101
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.636
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        41216.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.888
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        41216.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        29.715
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        49664.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.485
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        41216.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.615
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        41216.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        29.555
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        49664.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.595
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        41216.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.782
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        41216.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        29.473
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        49664.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.535
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        41216.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.569
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        41216.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        29.452
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        49664.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.746
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39424.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.699
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39424.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        33.002
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.676
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39424.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.747
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39424.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        32.927
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.646
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39424.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.762
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39424.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        33.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.858
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39424.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.397
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39424.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        32.963
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        17.189
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        71680.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        17.693
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        71680.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        182.05
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        110592.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        17.378
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        71680.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        17.791
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        71680.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.62
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        110592.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        17.318
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        71680.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        17.789
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        71680.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.866
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        110592.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        17.617
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        71680.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        17.871
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        71680.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.396
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        110592.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.663
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        36352.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.659
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        36352.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.082
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39936.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.476
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        36352.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.232
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        36352.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.182
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39936.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.784
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        36352.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.652
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        36352.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.08
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39936.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.515
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        36352.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.716
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        36352.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.175
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39936.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.873
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        54272.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.794
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        54272.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        90.562
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75776.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.879
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        54272.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.198
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        54272.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        91.394
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75776.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.902
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        54272.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.624
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        54272.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        90.273
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75776.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.863
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        54272.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.767
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        54272.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        91.506
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75776.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.62
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        47104.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.464
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        47104.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        97.304
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        61440.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.603
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        47104.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.355
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        47104.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        97.666
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        61440.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.577
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        47104.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.403
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        47104.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        96.997
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        61440.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.607
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        47104.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.289
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        47104.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        97.01
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        61440.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.195
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        90112.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        51.079
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        90112.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        673.685
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        147456.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.44
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        90112.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        51.202
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        90112.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        673.024
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        147456.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.392
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        90112.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        51.229
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        90112.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        672.778
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        147456.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.304
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        90112.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        51.214
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        90112.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        672.221
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        147456.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.735
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        42280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.608
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        42280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        42.029
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        51792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.949
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        42280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.746
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        42280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        42.159
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        51792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.661
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        42280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.685
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        42280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        42.278
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        51792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.67
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        42280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.892
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        42280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        42.301
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        51792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        26.532
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        87864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        25.734
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        87864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        268.823
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        142960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        26.509
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        87864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        26.089
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88440.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        268.702
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        143536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        26.471
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        87864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        25.756
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        87864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        270.636
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        142960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        26.321
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        87864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        25.889
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        87864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        270.315
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        142960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.703
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        66864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.138
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        66864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        278.354
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        100960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        22.01
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        66864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.318
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        67440.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        278.24
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        100960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.922
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        66864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.156
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        67440.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        277.207
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        100960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.921
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        66864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.29
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        67440.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        277.503
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        100960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        155.916
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        137536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        143.871
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        137536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2007.675
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        242304.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        154.712
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        137536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        146.066
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        137536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2006.257
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        242304.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        154.961
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        137536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        145.788
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        137536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2008.219
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        242304.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        155.66
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        137536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        145.984
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        137536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2007.877
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        242304.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        160.3
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        68353.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        143.004
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        156.269
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        152.347
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        141.205
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.454
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.246
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        73473.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        128.514
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.897
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.588
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        72961.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.043
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.62
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        138.236
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        156.494
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.567
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.768
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        73473.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.164
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        147.548
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.705
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        72961.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        142.052
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        128.395
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        138.899
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        140.205
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.577
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.033
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        73473.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.156
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        150.211
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.788
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        72961.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        146.194
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.542
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.776
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.179
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.758
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.68
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        73473.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        126.155
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        142.577
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        159.614
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        87297.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        131.892
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        128.703
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.36
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        183.537
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.456
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        159.103
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112897.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        151.624
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        152.802
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        129.494
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        108801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        147.969
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        151.582
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        139.474
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        126.08
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        153.098
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.064
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112897.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        149.684
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.11
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.134
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        108801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.819
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        134.831
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        178.97
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.149
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.757
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        190.774
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112897.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        169.532
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        148.776
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        164.773
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        108801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        148.954
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.259
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        131.056
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        140.309
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        166.129
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        144.774
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112897.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        139.264
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        158.658
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.97
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        110593.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        132.846
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.76
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.209
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.55
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.384
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.241
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121857.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.393
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.384
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.139
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121345.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.338
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.436
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        126.64
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.026
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        129.603
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.303
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121857.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.954
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.406
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.881
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121345.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.657
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        131.696
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.928
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.429
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.428
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        129.731
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121857.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        131.418
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.867
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        93.579
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121345.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        97.008
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        145.751
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.176
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        132.456
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        128.638
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.857
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121857.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        138.848
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        142.712
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        144.429
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        210945.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        140.426
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.818
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        146.258
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        145.591
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        139.114
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.779
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        387073.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        350.037
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        350.291
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.203
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        382977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.967
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.128
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.495
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.187
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.457
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        350.052
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        387073.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        350.458
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        350.063
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        105.97
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        382977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.002
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.501
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.644
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.275
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.527
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.32
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        387073.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.945
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        350.32
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.737
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        382977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.302
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.967
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.876
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        125.047
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.753
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.965
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        387073.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        350.192
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        350.35
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.829
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        281089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.232
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.392
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.963
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.976
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.332
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.045
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        83457.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.918
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.315
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        98.654
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81409.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.097
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.333
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.951
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.187
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.771
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.295
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        83457.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.261
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.189
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.15
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81409.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.576
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.928
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.475
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.626
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        105.83
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.586
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        83457.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        128.422
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.699
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.813
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81409.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.175
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.292
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.389
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.055
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.461
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.206
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        83457.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        126.207
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.382
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.282
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        106497.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.531
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        96.909
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.947
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.296
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.057
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        189.794
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        144385.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        190.31
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        190.425
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.435
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        128001.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.726
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.868
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.96
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.214
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.979
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        190.438
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        144385.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        190.088
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        190.339
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.192
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        128001.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.281
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.125
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.344
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        126.558
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.052
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        189.994
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        144385.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        190.995
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        190.979
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.543
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        128001.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.525
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.454
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.935
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.627
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.732
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        190.157
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        144385.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        189.962
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        190.215
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.313
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        135169.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.738
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.796
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.079
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.72
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.427
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        182.736
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        180225.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        180.846
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        182.044
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.583
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        178177.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.939
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.142
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.181
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.066
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.312
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        182.251
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        180225.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.882
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        182.073
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        125.127
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        178177.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.881
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.982
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.032
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.442
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.328
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.5
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        180225.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        182.52
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        183.216
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.72
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        178177.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.08
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.917
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.798
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.221
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.831
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        182.268
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        180225.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.088
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.752
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.913
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.844
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        131.713
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.681
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.523
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.974
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        941.575
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        466945.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        940.987
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        940.749
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.798
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        450561.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        138.154
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        139.168
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.865
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.421
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.999
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        940.364
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        466945.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        940.78
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        940.561
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.86
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        450561.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        148.292
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        138.405
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.097
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.722
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        144.481
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        941.351
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        466945.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        939.784
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        941.226
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.756
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        450561.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.02
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        138.899
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.913
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.373
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.259
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        941.333
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        466945.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        941.84
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        941.023
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.881
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327833.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.103
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.159
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.146
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        93.805
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.922
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        126.749
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        109145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.36
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.194
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.806
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        103145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        88.148
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.999
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.36
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.413
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.307
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.702
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        109145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.235
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.23
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.811
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        103145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.646
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        128.779
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.983
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.773
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.629
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.345
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        109145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.359
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.567
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        105.043
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        103145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        105.936
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        105.147
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.089
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.788
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.95
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.636
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        109145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.646
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.185
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.747
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156473.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.1
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.028
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157497.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.952
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157497.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.118
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.799
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157497.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.113
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        227017.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        458.785
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        248305.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        459.341
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        248881.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.122
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        179361.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.436
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157265.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.471
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157553.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.864
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        98.101
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157265.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        92.708
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        465.262
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        225401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        462.565
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        462.471
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.183
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        177689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.063
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.257
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.219
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.732
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157265.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.505
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        465.592
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        225401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.956
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        462.881
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.462
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        177689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.267
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        97.967
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        95.628
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.038
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157265.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.206
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        465.652
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        225401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        462.295
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        462.773
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.313
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        198689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.659
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.954
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.292
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.37
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.354
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        462.023
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        330977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        462.756
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.389
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.662
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        324401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.996
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        241033.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.802
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240457.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.483
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.122
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.791
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.808
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        330689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.004
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.847
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        126.143
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        324401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.634
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        126.594
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.642
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.304
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        94.193
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.579
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        330689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.967
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        462.365
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.284
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        324401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.1
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.514
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.737
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.634
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.242
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.559
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        330401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.017
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.544
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        264.824
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        452417.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        264.845
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        265.635
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        255.572
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        253.808
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        253.929
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2135.858
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        672449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2134.836
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2182.823
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        264.598
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        624449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        264.688
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        264.204
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        255.193
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        253.58
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        253.877
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2146.611
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        672449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2137.91
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2133.168
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        265.005
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        624449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        264.888
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        264.698
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        255.284
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        253.873
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.305
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2128.819
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        672449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2141.707
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2133.3
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        265.405
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        624449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        264.811
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        264.988
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.909
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        253.492
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.298
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2146.689
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        672449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2141.207
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2178.638
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  }
]