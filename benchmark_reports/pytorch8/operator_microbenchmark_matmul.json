[
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.515
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34048.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.649
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34048.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.776
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.411
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34048.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.342
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34048.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.753
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.39
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34048.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.297
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34048.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.756
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.531
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34048.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.302
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34048.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.775
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.518
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        41216.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.688
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        41216.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        29.355
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        49664.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.428
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        41216.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.372
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        41216.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        29.365
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        49664.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.501
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        41216.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.471
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        41216.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        29.294
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        49664.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.471
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        41216.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.409
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        41216.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        29.377
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        49664.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.879
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39424.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.899
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39424.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        32.699
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.775
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39424.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.915
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39424.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        32.79
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.865
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39424.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.019
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39424.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        32.73
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.712
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39424.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.794
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39424.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        32.78
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        17.163
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        71680.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        17.528
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        71680.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.609
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        110592.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        17.628
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        71680.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        17.564
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        71680.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        182.131
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        110592.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        17.3
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        71680.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        17.698
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        71680.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.533
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        110592.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        17.935
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        71680.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        17.688
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        71680.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.167
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        110592.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.52
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        36352.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.581
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        36352.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        20.835
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39936.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.499
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        36352.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.344
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        36352.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        20.853
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39936.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.442
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        36352.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.352
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        36352.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        20.862
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39936.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.452
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        36352.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.356
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        36352.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        20.912
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39936.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.719
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        54272.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.472
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        54272.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        89.932
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75776.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.879
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        54272.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.648
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        54272.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        91.296
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75776.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.742
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        54272.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.597
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        54272.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        90.322
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75776.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.735
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        54272.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.861
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        54272.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        90.824
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75776.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.496
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        47104.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.334
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        47104.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        97.202
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        61440.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.5
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        47104.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.356
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        47104.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        97.116
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        61440.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.498
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        47104.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.358
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        47104.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        97.923
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        61440.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.465
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        47104.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.391
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        47104.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        97.983
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        61440.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        52.976
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        90112.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        50.749
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        90112.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        670.37
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        147456.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.322
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        90112.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        51.015
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        90112.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        669.2
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        147456.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.395
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        90112.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        50.943
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        90112.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        669.984
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        147456.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        53.21
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        90112.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        50.944
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        90112.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        669.46
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        147456.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.668
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        42280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.51
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        42280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        42.506
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        51792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.686
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        42280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.485
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        42280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        42.288
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        51792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.566
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        42280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.548
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        42280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        42.345
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        51792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.487
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        42280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        9.475
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        42280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        41.97
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        51792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        26.4
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        87864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        25.541
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        87864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        268.089
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        142960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        26.514
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        87864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        25.96
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88440.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        268.482
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        143536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        26.193
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        87864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        25.813
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        87864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        270.259
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        142960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        26.189
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        87864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        25.824
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        87864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        268.559
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        142960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.547
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        66864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.011
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        66864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        277.744
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        100960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.852
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        66864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.23
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        67440.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        278.359
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        100960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.851
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        66864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.224
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        67440.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        277.024
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        100960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.812
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        66864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.453
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        67440.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        278.176
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        100960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        155.602
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        137536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        145.364
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        137536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2008.491
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        242304.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        154.695
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        137536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        145.551
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        137536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2008.533
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        242304.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        154.963
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        137536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        145.822
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        137536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2009.898
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        242304.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        155.038
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        137536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        145.522
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        137536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2009.419
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        242304.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.723
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        68353.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.751
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.61
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.448
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.446
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.474
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.965
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        73473.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.593
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.29
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.083
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        72961.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.654
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.716
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        83.846
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.534
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.776
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.861
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        73473.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        97.9
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        95.698
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.676
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        72961.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.402
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.035
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.832
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.067
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.592
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.017
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        73473.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        129.437
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.759
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.579
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        72961.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.019
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.678
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.164
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.944
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.978
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.304
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        73473.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.041
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.596
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        97.776
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        87297.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.395
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.068
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.264
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.531
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.026
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.557
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112897.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        125.765
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.282
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.502
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        108801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.835
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.196
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.747
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.061
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.522
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.348
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112897.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        129.187
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.211
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.75
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        108801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.695
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.985
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.164
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.682
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.705
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.238
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112897.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.718
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.65
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.844
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        108801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.504
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.66
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.212
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.335
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.097
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.574
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112897.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.508
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.163
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.116
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        110593.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.319
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.164
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.022
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.146
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        93.3
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.756
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121857.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.618
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.533
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.57
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121345.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.034
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.476
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        84.675
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.708
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.154
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.252
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121857.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.53
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.984
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.719
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121345.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.965
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        94.467
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.323
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.068
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.088
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.998
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121857.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.243
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.108
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.843
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121345.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.898
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.479
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.69
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.255
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        87.869
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.805
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121857.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.555
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.097
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.006
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        210945.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.701
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.496
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.281
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.476
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.962
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.944
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        387073.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.583
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.655
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.289
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        382977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.438
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.191
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.425
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        126.734
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.691
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.439
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        387073.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        350.059
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.498
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.368
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        382977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.271
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.684
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.813
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.79
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.282
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.877
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        387073.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        348.851
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.586
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.126
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        382977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.908
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.459
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.137
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        125.517
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.967
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.403
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        387073.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.648
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.755
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.769
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        281089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.711
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.81
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.886
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.52
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        83.665
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.276
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        83457.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.998
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.394
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.379
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81409.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.557
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.719
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.015
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.087
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.655
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.755
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        83457.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.012
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.684
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.284
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81409.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.783
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.957
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.345
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.582
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.633
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.299
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        83457.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.936
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.182
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        90.031
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81409.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.025
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.268
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        97.816
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        98.184
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.089
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.015
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        83457.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.93
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.449
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.592
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        106497.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        95.041
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.066
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.202
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.462
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.821
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        189.091
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        144385.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        189.941
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        190.29
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        93.041
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        128001.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        90.896
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.466
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.024
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.988
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.047
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        188.841
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        144385.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        189.716
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        190.358
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        98.309
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        128001.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.834
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.518
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.93
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.299
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.723
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        188.807
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        144385.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        189.853
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        190.408
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.989
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        128001.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.944
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.596
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.664
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.731
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.71
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        189.119
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        144385.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        189.768
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        189.971
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.599
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        135169.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        86.359
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.821
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.452
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        93.331
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.551
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.499
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        180225.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.205
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.901
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        93.575
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        178177.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.368
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.297
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        83.518
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        97.715
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.699
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        182.012
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        180225.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.658
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        180.745
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.757
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        178177.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.43
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.036
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.23
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.627
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.872
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.28
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        180225.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.362
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        182.004
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.216
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        178177.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.596
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.595
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.174
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        105.33
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.076
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.026
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        180225.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.624
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.978
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.838
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.522
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.693
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.618
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.402
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.906
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        940.108
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        466945.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        940.423
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        939.274
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.364
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        450561.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.597
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.946
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.707
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.262
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.42
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        939.785
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        466945.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        939.938
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        941.39
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.111
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        450561.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.043
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.551
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.533
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.74
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.304
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        941.091
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        466945.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        940.578
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        938.817
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.542
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        450561.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.5
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.986
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.115
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.689
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.491
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        938.981
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        466945.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        939.988
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        940.841
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.847
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327833.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.45
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.011
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        126.523
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.84
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        93.392
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.999
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        109145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.73
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        125.965
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.221
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        103145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.772
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.181
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.39
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.78
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.019
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        128.254
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        109145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        134.488
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.877
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.697
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        103145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.562
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.732
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.796
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.635
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.137
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.473
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        109145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.213
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.127
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.373
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        103145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.624
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.614
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.084
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.034
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.363
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.763
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        109145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.019
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.705
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.979
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156473.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.689
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.389
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157497.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.046
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157497.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.141
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.95
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157497.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        463.307
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        227017.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.989
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        248305.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.047
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        248881.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.444
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        179361.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.231
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157265.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.957
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157553.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.381
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.903
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157265.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.808
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        463.971
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        225401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        462.699
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.054
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.928
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        177689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.723
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.757
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.914
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.87
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157265.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.072
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        463.667
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        225401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        462.684
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.89
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.117
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        177689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.791
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.794
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.962
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        95.294
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157265.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.724
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        464.161
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        225401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        462.756
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.408
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.399
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        198689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.489
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.841
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.664
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.253
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.895
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.285
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        330977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.489
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.498
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.85
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        324401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.724
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        241033.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.685
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240457.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.196
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.864
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.433
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.978
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        330689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.978
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.946
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.273
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        324401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.449
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        98.036
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        125.939
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.044
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.054
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        457.69
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        330689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        458.293
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        457.833
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.715
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        324401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.605
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.523
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.825
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.815
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.97
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.044
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        330401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.352
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.198
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        262.795
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        452417.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        263.692
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        263.759
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.425
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.307
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        253.785
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2127.484
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        672449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2110.733
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2126.416
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        263.74
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        624449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        263.923
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        263.835
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.19
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        252.768
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        253.067
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2140.433
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        672449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2145.372
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2127.798
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        263.642
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        624449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        264.224
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        264.274
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.653
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        252.753
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        253.095
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2144.681
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        672449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2137.588
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2141.796
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        264.098
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        624449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        264.044
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        263.814
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.149
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        252.727
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        252.957
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2179.961
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        672449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2178.557
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2138.393
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": false
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  }
]