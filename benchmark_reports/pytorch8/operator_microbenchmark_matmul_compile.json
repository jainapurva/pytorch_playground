[
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3203.108
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        768.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        3224.411
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        768.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.57
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34816.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.828
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        33792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.073
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        33792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.558
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34816.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.738
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        33792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.909
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        33792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.679
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34816.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.867
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        33792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.982
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        33792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.713
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        34816.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.095
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.298
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        17.194
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45568.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.946
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.109
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        16.148
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45568.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.011
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.205
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        16.015
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45568.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.959
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.02
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        16.388
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45568.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.359
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.474
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        24.93
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45568.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.553
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.582
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        24.953
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45568.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.448
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.531
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        25.002
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45568.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.509
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.582
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39168.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        25.014
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45568.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.449
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        69632.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.611
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        69632.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        65.104
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        106496.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.178
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        69632.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.532
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        69632.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.814
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        106496.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.411
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        69632.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.641
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        69632.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        66.416
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        106496.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.163
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        69632.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.891
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        69632.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        67.054
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        106496.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.15
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.613
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        15.884
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        37888.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.079
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.124
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        16.219
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        37888.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.791
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.002
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        15.928
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        37888.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.944
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.038
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        35328.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        15.822
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        37888.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.865
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.242
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        24.387
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        59392.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.889
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.086
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.73
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        59392.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.889
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.081
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.455
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        59392.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.97
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.02
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        21.471
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        59392.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.892
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.046
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        50.282
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        59392.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.863
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.954
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        50.556
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        59392.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.854
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.064
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        50.233
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        59392.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.727
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.09
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        46080.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        49.501
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        59392.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.909
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81920.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.912
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81920.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.872
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        131072.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.482
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81920.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        17.98
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81920.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.895
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        131072.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.81
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81920.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.29
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81920.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.345
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        131072.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        19.059
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81920.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.149
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81920.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.165
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        131072.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.881
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.109
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        15.136
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.903
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.124
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        15.143
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.055
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.061
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        15.133
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.03
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        11.045
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        39280.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        15.147
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        45792.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        19.284
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.218
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.209
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        94960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        19.142
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.342
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.277
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95248.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        19.119
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.207
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.238
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        94960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        19.181
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        18.547
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        10.73
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        94960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.409
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.347
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.273
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        16.51
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.296
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.961
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        94960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.402
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.029
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        64440.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.729
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.423
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.949
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        63864.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.587
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        94960.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        82.321
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        113536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        75.271
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        113536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.231
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        194304.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        79.528
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        113536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        77.093
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        113536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.966
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        194304.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        82.352
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        113536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        75.798
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        113536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        13.656
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        194304.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        80.821
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        113536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        76.906
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        113536.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        12.767
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "inference",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        194304.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.882
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        68353.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.194
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.761
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.141
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.026
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.521
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.531
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        73473.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.659
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.366
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.859
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        72961.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        130.574
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.522
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.51
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.18
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.353
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.629
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        73473.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.523
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.698
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.417
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        72961.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.046
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.823
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.569
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.394
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.609
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        93.636
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        73473.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.364
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        125.191
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        105.324
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        72961.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.843
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        97.407
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.779
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.101
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        96.67
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        70657.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.173
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        73473.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.976
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        129.828
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        75777.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.185
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        87297.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        93.148
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.364
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.053
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.756
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.731
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        126.475
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112897.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        95.355
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.53
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.477
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        108801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.246
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.207
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.043
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.118
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.317
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.334
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112897.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.475
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.145
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.77
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        108801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        128.061
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.388
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.865
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.246
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        98.812
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.02
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112897.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.367
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.404
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.834
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        108801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.724
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.349
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.469
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.851
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.426
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        95745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.549
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112897.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.897
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.595
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        125953.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.393
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        110593.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.919
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.822
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.383
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.017
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.704
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.936
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121857.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.594
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.876
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        97.62
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121345.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        95.575
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.439
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.544
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.449
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.289
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.605
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121857.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.053
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.044
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.041
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121345.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.237
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.233
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.219
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.781
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.535
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        105.91
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121857.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.775
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.804
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.364
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121345.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        84.977
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        93.041
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.576
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.657
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.601
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        102913.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.853
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        121857.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        97.196
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.752
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        140289.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.188
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        210945.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.333
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        92.074
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        105.927
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.64
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.027
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.103
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        387073.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.218
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.502
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.041
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        382977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.846
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.715
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.512
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.266
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.982
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.132
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        387073.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.504
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.278
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.248
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        382977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.854
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.292
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.984
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.116
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.895
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        348.91
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        387073.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.484
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.271
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.257
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        382977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.846
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.234
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.022
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.623
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.67
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        348.985
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        387073.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.265
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        349.02
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 256, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M256_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        491521.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.317
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        281089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        105.956
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.409
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.453
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.397
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.893
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        98.043
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        83457.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.494
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.949
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.28
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81409.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.099
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.07
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.157
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.647
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        99.707
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        100.566
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        83457.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.944
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.509
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.802
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81409.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        98.17
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.582
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.6
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        93.873
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.143
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.99
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        83457.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.501
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.31
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.4
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        81409.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.057
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.806
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.152
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.243
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.479
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        76801.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.199
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        83457.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.525
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.357
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        88065.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        115.499
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        106497.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.599
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.721
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.443
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.63
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.922
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        188.632
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        144385.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        188.625
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        188.715
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.524
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        128001.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.484
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.854
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.707
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        98.831
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.63
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        188.619
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        144385.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        189.447
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        189.62
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.114
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        128001.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.22
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.499
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.152
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.626
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        95.046
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        188.392
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        144385.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        189.401
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        189.688
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.233
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        128001.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.517
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.084
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        111.289
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.281
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.074
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        112641.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        188.042
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        144385.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        188.606
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        188.829
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        159745.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        105.046
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        135169.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        105.619
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.36
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.96
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        97.893
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        95.47
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        180.892
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        180225.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        180.772
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        180.862
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.346
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        178177.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.727
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.476
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        105.046
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.631
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.334
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        180.962
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        180225.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.094
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        180.826
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.598
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        178177.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.404
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.157
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.776
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.307
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.245
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        180.696
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        180225.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.629
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        181.843
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        89.698
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        178177.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.433
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.293
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.456
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        126.748
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.073
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        141313.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        182.599
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        180225.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        182.025
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        182.039
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        217089.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.677
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        278529.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.435
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.561
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        145.423
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.726
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.925
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        939.929
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        466945.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        939.984
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        938.176
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.605
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        450561.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.531
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.23
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.604
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.574
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.151
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        939.899
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        466945.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        940.095
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        941.397
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.597
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        450561.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.756
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.36
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.074
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.233
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.395
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        939.318
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        466945.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        940.456
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        939.235
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        138.05
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        450561.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.003
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        137.352
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.261
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        135.933
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        136.449
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        941.243
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        466945.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        940.265
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        941.109
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 1024, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M1024_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        589825.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.232
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        327833.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.6
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.492
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.824
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.407
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.82
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.391
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        109145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.675
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.881
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.765
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        103145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.674
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.111
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.361
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.614
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.653
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.491
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        109145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        128.508
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        132.096
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        87.654
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        103145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.587
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.483
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        107.554
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.417
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.884
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.867
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        109145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        126.655
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.158
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.033
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        103145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.677
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        106.988
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.317
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.172
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.494
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        92609.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.715
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        109145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        127.534
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        124.091
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        119681.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.069
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156473.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.944
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        85.312
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157497.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        105.893
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157497.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.81
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.563
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157497.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        463.606
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        227017.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.488
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        248305.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        462.405
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        248881.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.028
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        179361.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.785
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157265.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.521
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157553.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.812
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.416
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157265.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.185
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        463.913
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        225401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        463.059
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.401
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        118.3
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        177689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.335
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.64
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        101.707
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.51
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157265.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        98.68
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        464.245
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        225401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        462.901
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.786
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.918
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        177689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.32
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        116.746
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        113.785
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.106
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        157265.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.453
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        156977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        464.271
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        225401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        462.429
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.241
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 512, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N512_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        246977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        103.061
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        198689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.616
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        112.862
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        121.808
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.989
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.215
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.357
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        330977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.472
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.206
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        102.439
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        324401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.795
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        241033.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        89.975
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240457.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        108.829
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        109.32
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        114.44
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.541
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        330689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.745
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.773
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.438
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        324401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        119.784
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.848
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        120.917
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        110.221
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        88.94
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.98
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        330689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        461.109
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.534
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.279
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        324401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        122.459
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240113.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.202
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        104.209
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        123.719
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        117.539
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        240689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.368
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        330401.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.534
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414977.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        460.85
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 512, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K512_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        414689.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        264.904
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        452417.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        264.472
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        263.753
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.317
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.689
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.02
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2175.099
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        672449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2144.964
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2102.807
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        263.569
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        624449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        263.823
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        264.387
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.372
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.05
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.063
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2155.438
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        672449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2141.244
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2141.512
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: False, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aFalse_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        264.016
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        624449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        264.592
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        264.048
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.489
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.22
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.125
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2140.64
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        672449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2132.818
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2135.305
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: True, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bTrue_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        263.988
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        624449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        263.781
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        263.877
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        254.796
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        253.505
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        253.841
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "bfloat16",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.bfloat16",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.bfloat16_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        454145.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2141.926
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwdall",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        672449.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2142.171
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd1",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "latency",
      "unit": "us",
      "benchmark_values": [
        2178.85
      ],
      "target_value": null
    }
  },
  {
    "benchmark": {
      "name": "PyTorch operator microbenchmark",
      "mode": "training",
      "dtype": "float32",
      "extra_info": {
        "input_config": "M: 3000, N: 4096, K: 4096, trans_a: True, trans_b: False, device: cuda, dtype: torch.float32",
        "device": "cuda",
        "arch": "NVIDIA H100",
        "use_compile": true
      }
    },
    "model": {
      "name": "matmul_M3000_N4096_K4096_trans_aTrue_trans_bFalse_cuda_dtypetorch.float32_bwd2",
      "type": "micro-benchmark",
      "origins": [
        "pytorch"
      ]
    },
    "metric": {
      "name": "peak memory",
      "unit": "KB",
      "benchmark_values": [
        842753.0
      ],
      "target_value": null
    }
  }
]